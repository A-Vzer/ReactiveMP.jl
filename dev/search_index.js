var documenterSearchIndex = {"docs":
[{"location":"getting-started/#Getting-started","page":"Getting started","title":"Getting started","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"ReactiveMP.jl is a Julia package for Bayesian Inference on Factor Graphs by Message Passing. It supports both exact and variational inference algorithms.","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"ReactiveMP package is a successor of the ForneyLab package. It follows the same ideas and concepts for message-passing based inference, but uses new reactive and efficient message passing implementation under the hood. The API between two packages is different due to a better flexibility, performance and new reactive approach for solving inference problems.","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"This page provides the necessary information you need to get started with ReactiveMP. We will show the general approach to solving inference problems with ReactiveMP by means of a running example: inferring the bias of a coin.","category":"page"},{"location":"getting-started/#Installation","page":"Getting started","title":"Installation","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"Install ReactiveMP through the Julia package manager:","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"] add ReactiveMP","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"note: Note\nFor best user experience you also need to install GraphPPL, Rocket and Distributions packages.","category":"page"},{"location":"getting-started/#Example:-Inferring-the-bias-of-a-coin","page":"Getting started","title":"Example: Inferring the bias of a coin","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"The ReactiveMP approach to solving inference problems consists of three phases:","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"Model specification: ReactiveMP uses GraphPPL package for model specification part. It offers a domain-specific language to specify your probabilistic model.\nInference specification: ReactiveMP inference API has been designed to be as flexible as possible and it is compatible both with asynchronous infinite data streams and with static datasets. For most of the use cases it consists of the same simple building blocks. In this example we will show one of the many possible ways to infer your quantities of interest.\nInference execution: Given model specification and inference procedure it is pretty straightforward to use reactive API from Rocket to pass data to the inference backend and to run actual inference.","category":"page"},{"location":"getting-started/#Coin-flip-simulation","page":"Getting started","title":"Coin flip simulation","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"Let's start by creating some dataset. One approach could be flipping a coin N times and recording each outcome. For simplicity in this example we will use static pre-generated dataset. Each sample can be thought of as the outcome of single flip which is either heads or tails (1 or 0). We will assume that our virtual coin is biased, and lands heads up on 75% of the trials (on average).","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"First lets setup our environment by importing all needed packages:","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"using Rocket, GraphPPL, ReactiveMP, Distributions, Random","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"Next, lets define our dataset:","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"rng = MersenneTwister(42)\nn = 10\np = 0.75\ndistribution = Bernoulli(p)\n\ndataset = float.(rand(rng, Bernoulli(p), n))","category":"page"},{"location":"getting-started/#Model-specification","page":"Getting started","title":"Model specification","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"In a Bayesian setting, the next step is to specify our probabilistic model. This amounts to specifying the joint probability of the random variables of the system.","category":"page"},{"location":"getting-started/#Likelihood","page":"Getting started","title":"Likelihood","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"We will assume that the outcome of each coin flip is governed by the Bernoulli distribution, i.e.","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"y_i sim mathrmBernoulli(theta)","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"where y_i = 1 represents \"heads\", y_i = 0 represents \"tails\". The underlying probability of the coin landing heads up for a single coin flip is theta in 01.","category":"page"},{"location":"getting-started/#Prior","page":"Getting started","title":"Prior","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"We will choose the conjugate prior of the Bernoulli likelihood function defined above, namely the beta distribution, i.e.","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"theta sim Beta(a b)","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"where a and b are the hyperparameters that encode our prior beliefs about the possible values of theta. We will assign values to the hyperparameters in a later step.   ","category":"page"},{"location":"getting-started/#Joint-probability","page":"Getting started","title":"Joint probability","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"The joint probability is given by the multiplication of the likelihood and the prior, i.e.","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"P(y_1N θ) = P(θ) prod_i=1^N P(y_i  θ)","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"Now let's see how to specify this model using GraphPPL's package syntax.","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"\n# GraphPPL.jl export `@model` macro for model specification\n# It accepts a regular Julia function and builds an FFG under the hood\n@model function coin_model(n)\n\n    # `datavar` creates data 'inputs' in our model\n    # We will pass data later on to these inputs\n    # In this example we create a sequence of inputs that accepts Float64\n    y = datavar(Float64, n)\n    \n    # We endow θ parameter of our model with some prior\n    θ ~ Beta(2.0, 7.0)\n    \n    # We assume that outcome of each coin flip is governed by the Bernoulli distribution\n    for i in 1:n\n        y[i] ~ Bernoulli(θ)\n    end\n    \n    # We return references to our data inputs and θ parameter\n    # We will use these references later on during inference step\n    return y, θ\nend\n","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"As you can see, GraphPPL offers a model specification syntax that resembles closely to the mathematical equations defined above. We use datavar function to create \"clamped\" variables that take specific values at a later date. θ ~ Beta(2.0, 7.0) expression creates random variable θ and assigns it as an output of Beta node in the corresponding FFG. ","category":"page"},{"location":"getting-started/#Inference-specification","page":"Getting started","title":"Inference specification","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"Once we have defined our model, the next step is to use ReactiveMP API to infer quantities of interests. To do this, we need to specify inference procedure. ReactiveMP API is flexible in terms of inference specification and is compatible both with real-time inference processing and with statis datasets. In most of the cases for static datasets, as in our example, it consists of same basic building blocks:","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"Return variables of interests from model specification\nSubscribe on variables of interests posterior marginal updates\nPass data to the model\nUnsubscribe ","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"Here is an example of inference procedure:","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"function inference(data)\n    n = length(data)\n\n    # `coin_model` function from `@model` macro returns a reference to the model object and \n    # the same output as in `return` statement in the original function specification\n    model, (y, θ) = coin_model(n)\n    \n    # Reference for future posterior marginal \n    mθ = nothing\n\n    # `getmarginal` function returns an observable of future posterior marginal updates\n    # We use `Rocket.jl` API to subscribe on this observable\n    # As soon as posterior marginal update is available we just save it in `mθ`\n    subscription = subscribe!(getmarginal(θ), (m) -> mθ = m)\n    \n    # `update!` function passes data to our data inputs\n    update!(y, data)\n    \n    # It is always a good practice to unsubscribe and to \n    # free computer resources held by the subscription\n    unsubscribe!(subscription)\n    \n    # Here we return our resulting posterior marginal\n    return mθ\nend","category":"page"},{"location":"getting-started/#Inference-execution","page":"Getting started","title":"Inference execution","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"Here after everything is ready we just call our inference function to get a posterior marginal distribution over θ parameter in the model.","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"θestimated = inference(dataset)","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"println(\"mean: \", mean(θestimated))\nprintln(\"std:  \", std(θestimated))\nnothing #hide","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"using Plots, LaTeXStrings; theme(:default)\n\nrθ = range(0, 1, length = 1000)\n\np1 = plot(rθ, (x) -> pdf(Beta(2.0, 7.0), x), title=\"Prior\", fillalpha=0.3, fillrange = 0, label=L\"P\\:(\\theta)\", c=1,)\np2 = plot(rθ, (x) -> pdf(θestimated, x), title=\"Posterior\", fillalpha=0.3, fillrange = 0, label=L\"P\\:(\\theta|y)\", c=3)\n\nplot(p1, p2, layout = @layout([ a; b ]))","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"In our dataset we used 10 coin flips to estimate the bias of a coin. It resulted in a vague posterior distribution, however ReactiveMP scales very well for large models and factor graphs. We may use more coin flips in our dataset for better posterior distribution estimates:","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"dataset_100   = float.(rand(rng, Bernoulli(p), 100))\ndataset_1000  = float.(rand(rng, Bernoulli(p), 1000))\ndataset_10000 = float.(rand(rng, Bernoulli(p), 10000))\nnothing # hide","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"θestimated_100   = inference(dataset_100)\nθestimated_1000  = inference(dataset_1000)\nθestimated_10000 = inference(dataset_10000)\nnothing #hide","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"p3 = plot(title = \"Posterior\", legend = :topleft)\n\np3 = plot!(p3, rθ, (x) -> pdf(θestimated_100, x), fillalpha = 0.3, fillrange = 0, label = L\"P\\:(\\theta\\:|y_{1:100})\", c = 4)\np3 = plot!(p3, rθ, (x) -> pdf(θestimated_1000, x), fillalpha = 0.3, fillrange = 0, label = L\"P\\:(\\theta\\:|y_{1:1000})\", c = 5)\np3 = plot!(p3, rθ, (x) -> pdf(θestimated_10000, x), fillalpha = 0.3, fillrange = 0, label = L\"P\\:(\\theta\\:|y_{1:10000})\", c = 6)\n\nplot(p1, p3, layout = @layout([ a; b ]))","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"With larger dataset our posterior marginal estimate becomes more and more accurate and represents real value of the bias of a coin.","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"println(\"mean: \", mean(θestimated_10000))\nprintln(\"std:  \", std(θestimated_10000))\nnothing #hide","category":"page"},{"location":"getting-started/#Where-to-go-next?","page":"Getting started","title":"Where to go next?","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"There are a set of demos available in ReactiveMP repository that demonstrate the more advanced features of the package. Alternatively, you can head to the User guide which provides more detailed information of how to use ReactiveMP to solve inference problems.","category":"page"},{"location":"extending/#Extending-the-functionality","page":"Extending","title":"Extending the functionality","text":"","category":"section"},{"location":"extending/#Adding-a-new-type-of-node","page":"Extending","title":"Adding a new type of node","text":"","category":"section"},{"location":"extending/","page":"Extending","title":"Extending","text":"ReactiveMP.jl package exports the @node macro to create a simple factor node with fixed number of arguments.","category":"page"},{"location":"extending/","page":"Extending","title":"Extending","text":"@node macro accepts three arguments:","category":"page"},{"location":"extending/","page":"Extending","title":"Extending","text":"A functional form of the new node in form of a Julia type, e.g. Normal or typeof(+)\nA type of node: Stochastic or Deterministic\nA list of node arguments, e.g. [ out, mean, variance ]","category":"page"},{"location":"extending/","page":"Extending","title":"Extending","text":"note: Note\nBy convention a list of node arguments should start with out ","category":"page"},{"location":"extending/","page":"Extending","title":"Extending","text":"Examples:","category":"page"},{"location":"extending/","page":"Extending","title":"Extending","text":"@node GaussianMeanVariance Stochastic [ out, m, v ]\n@node typeof(+) Deterministic [ out, in1, in2 ]","category":"page"},{"location":"user-guide/#User-guide","page":"User guide","title":"User guide","text":"","category":"section"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"This user guide outlines the usage of ReactiveMP for solving inference problems. The content is divided in several parts:","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"Specifying a model\nSpecifying an inference procedure\nInference execution","category":"page"},{"location":"user-guide/#user-guide-model-specification","page":"User guide","title":"User guide: Model Specification","text":"","category":"section"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"Probabilistic models incorporate elements of randomness to describe an event or phenomenon by using random variables and probability theory. A probabilistic model can be represented visually by using probabilistic graphical models (PGMs). A factor graph is a type of PGM that is well suited to cast inference tasks in terms of graphical manipulations.","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"GraphPPL.jl is a Julia package presenting a model specification language for probabilistic models.","category":"page"},{"location":"user-guide/#Model-specification","page":"User guide","title":"Model specification","text":"","category":"section"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"The ReactiveMP uses GraphPPL library to simplify model specification. It is not necessary but highly recommended to use ReactiveMP in a combination with GraphPPL model specification library. The GraphPPL library exports a single @model macro for model specification. The @model macro accepts two arguments: model options (optionally) and the model specification itself in a form of regular Julia function. ","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"For example: ","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"# `@model` macro accepts an array of named options as a first argument and\n# a regular Julia function body as its second argument\n@model [ option1 = ..., option2 = ... ] function model_name(model_arguments...)\n    # model specification goes here\n    return ...\nend","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"Model options are optional and may be omitted:","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"@model function model_name(model_arguments...)\n    # model specification here\n    return ...\nend","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"that is equivalent to ","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"# Empty options if ommited\n@model [] function model_name(model_arguments...)\n    # model specification here\n    return ...\nend","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"The @model macro returns a regular Julia function (in this example model_name(model_arguments...)) that has the same signature and can be executed as usual. It returns a reference to a model object itself and a tuple of a user specified return variables, e.g:","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"@model function my_model(model_arguments...)\n    # model specification here\n    # ...\n    return x, y\nend","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"model, (x, y) = my_model(model_arguments...)","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"It is also important to note that any model should return something, such as variables or nodes. If a model doesn't return anything then an error will be raised during runtime.  model object might be useful to inspect model's factor graph and/or factor nodes and variables. It is also used in Bethe Free Energy score computation. If not needed it can be ommited with _ placeholder, eg:","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"_, (x, y) = my_model(model_arguments...)","category":"page"},{"location":"user-guide/#A-full-example-before-diving-in","page":"User guide","title":"A full example before diving in","text":"","category":"section"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"Before presenting the details of the model specification syntax, we show an example of a simple probabilistic model. Here we create a linear gaussian state space model with latent random variables x and noisy observations y:","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"@model [ options... ] function state_space_model(n_observations, noise_variance)\n\n    x = randomvar(n_observations)\n    y = datavar(Float64, n_observations)\n\n    x[1] ~ NormalMeanVariance(0.0, 100.0)\n\n    for i in 2:n_observations\n       x[i] ~ x[i - 1] + 1.0\n       y[i] ~ NormalMeanVariance(x[i], noise_variance)\n    end\n\n    return x, y\nend","category":"page"},{"location":"user-guide/#Graph-variables-creation","page":"User guide","title":"Graph variables creation","text":"","category":"section"},{"location":"user-guide/#Constants","page":"User guide","title":"Constants","text":"","category":"section"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"Any runtime constant passed to a model as a model argument will be automatically converted to a fixed constant in the graph model. This convertion happens every time when model specification identifies a constant. Sometimes it might be useful to create constants by hand (e.g. to avoid copying large matrices across the model and to avoid extensive memory allocations).","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"You can create a constant within a model specification macro with constvar() function. For example:","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"c = constvar(1.0)\n\nfor i in 2:n\n    x[i] ~ x[i - 1] + c # Reuse the same reference to a constant 1.0\nend","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"Additionally you can specify an extra ::ConstVariable type for some of the model arguments. In this case macro automatically converts them to a single constant using constvar() function. E.g.:","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"@model function model_name(nsamples::Int, c::ConstVariable)\n    # ...\n    # no need to call for a constvar() here\n    for i in 2:n\n        x[i] ~ x[i - 1] + c # Reuse the same reference to a constant `c`\n    end\n    # ...\n    return ...\nend","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"note: Note\n::ConstVariable does not restrict an input type of an argument and does not interfere with multiple dispatch. In this example c can have any type, e.g. Int.","category":"page"},{"location":"user-guide/#Data-variables","page":"User guide","title":"Data variables","text":"","category":"section"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"It is important to have a mechanism to pass data values to the model. You can create data inputs with datavar() function. As a first argument it accepts a type specification and optional dimensionality (as additional arguments or as a tuple).","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"Examples: ","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"y = datavar(Float64) # Creates a single data input with `y` as identificator\ny = datavar(Float64, n) # Returns a vector of  `y_i` data input objects with length `n`\ny = datavar(Float64, n, m) # Returns a matrix of `y_i_j` data input objects with size `(n, m)`\ny = datavar(Float64, (n, m)) # It is also possible to use a tuple for dimensionality, it is an equivalent of the previous line","category":"page"},{"location":"user-guide/#Random-variables","page":"User guide","title":"Random variables","text":"","category":"section"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"There are several ways to create random variables. The first one is an explicit call to randomvar() function. By default it doesn't accept any argument, creates a single random variable in the model and returns it. It is also possible to pass dimensionality arguments to randomvar() function in the same way as for the datavar() function.","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"Examples: ","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"x = randomvar() # Returns a single random variable which can be used later in the model\nx = randomvar(n) # Returns an vector of random variables with length `n`\nx = randomvar(n, m) # Returns a matrix of random variables with size `(n, m)`\nx = randomvar((n, m)) # It is also possible to use a tuple for dimensionality, it is an equivalent of the previous line","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"The second way to create a random variable is to use the ~ operator. If the random variable hasn't been created yet, ~ operator will be creat it automatically during the creation of the node. Read more about the ~ operator in the next section.","category":"page"},{"location":"user-guide/#Node-creation","page":"User guide","title":"Node creation","text":"","category":"section"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"Factor nodes (or local functions) are used to define a relationship between random variables and/or constants and data inputs. In most of the cases a factor node defines a probability distribution over selected random variables. ","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"We model a random variable by a probability distribution using the ~ operator. For example, to create a random variable y which is modeled by a Normal distribution, where its mean and variance are controlled by the random variables m and v respectively, we define","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"m = randomvar()\nv = randomvar()\ny ~ NormalMeanVariance(m, v) # Creates a `y` random variable automatically","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"It is also possible to use a deterministic relationships between random variables:","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"a = randomvar()\nb = randomvar()\nc ~ a + b # Here with the help of `~` operator we explictly say that `c` is a random variable too","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"note: Note\nThe GraphPPL.jl package uses the ~ operator for modelling both stochastic and deterministic relationships between random variables.","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"The @model macro automatically resolves any inner function calls into anonymous extra nodes. It is also worth to note that inference backend will try to optimize inner deterministic function calls in the case where all arguments are constants or data inputs. For example:","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"noise ~ NormalMeanVariance(mean, inv(precision)) # Will create a non-linear node `inv` in case if `precision` is a random variable. Won't create an additional non-linear node in case if `precision` is a constant or data input.","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"It is possible to use any functional expression within the ~ operator arguments list. The only one exception is the ref expression (e.g x[i] or x[i, j]). In principle x[i] expression is equivalent to getindex(x, i) and therefore might be treated as a factor node with getindex as local function, however all ref expressions within the ~ operator arguments list are left untouched during model parsing. This means that the model parser will not create unnecessary nodes when only simple indexing is involved.","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"y ~ NormalMeanVariance(x[i - 1], variance) # While in principle `x[i - 1]` is equivalent to (`getindex(x, -(i, 1))`) model parser will leave it untouched and won't create any anonymous nodes for this expression.\n\ny ~ NormalMeanVariance(A * x[i - 1], variance) # This example will create a `*` anonymous node (in case if x[i - 1] is a random variable) and leave `x[i - 1]` untouched.","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"It is also possible to return a node reference from the ~ operator with the following syntax:","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"node, y ~ NormalMeanVariance(mean, var)","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"Having a node reference can be useful in case the user wants to return it from a model and to use it later on to specify initial joint marginal distributions.","category":"page"},{"location":"user-guide/#Node-creation-options","page":"User guide","title":"Node creation options","text":"","category":"section"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"To pass optional arguments to the node creation constructor the user can use the where { options...  } specification syntax.","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"Example:","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"y ~ NormalMeanVariance(y_mean, y_var) where { q = q(y_mean)q(y_var)q(y) } # mean-field factorisation over q","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"A list of all available options is presented below:","category":"page"},{"location":"user-guide/#Factorisation-constraint-option","page":"User guide","title":"Factorisation constraint option","text":"","category":"section"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"Users can specify a factorisation constraint over the approximate posterior q for variational inference. The general syntax for factorisation constraints over q is the following:","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"variable ~ Node(node_arguments...) where { q = RecognitionFactorisationConstraint }","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"where RecognitionFactorisationConstraint can be one the following:","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"MeanField()","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"Automatically specifies a mean-field factorisation","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"Example:","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"y ~ NormalMeanVariance(y_mean, y_var) where { q = MeanField() }","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"FullFactorisation()","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"Automatically specifies a full factorisation (this is the default)","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"Example:","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"y ~ NormalMeanVariance(y_mean, y_var) where { q = FullFactorisation() }","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"q(μ)q(v)q(out) or q(μ) * q(v) * q(out)","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"A user can specify any factorisation he wants as the multiplication of q(interface_names...) factors. As interface names the user can use the interface names of an actual node (read node's documentation), its aliases (if available) or actual random variable names present in the ~ operator expression.","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"Examples: ","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"# Using interface names of a `NormalMeanVariance` node for factorisation constraint. \n# Call `?NormalMeanVariance` to know more about interface names for some node\ny ~ NormalMeanVariance(y_mean, y_var) where { q = q(μ)q(v)q(out) }\ny ~ NormalMeanVariance(y_mean, y_var) where { q = q(μ, v)q(out) }\n\n# Using interface names aliases of a `NormalMeanVariance` node for factorisation constraint. \n# Call `?NormalMeanVariance` to know more about interface names aliases for some node\n# In general aliases correspond to the function names for distribution parameters\ny ~ NormalMeanVariance(y_mean, y_var) where { q = q(mean)q(var)q(out) }\ny ~ NormalMeanVariance(y_mean, y_var) where { q = q(mean, var)q(out) }\n\n# Using random variables names from `~` operator expression\ny ~ NormalMeanVariance(y_mean, y_var) where { q = q(y_mean)q(y_var)q(y) }\ny ~ NormalMeanVariance(y_mean, y_var) where { q = q(y_mean, y_var)q(y) }\n\n# All methods can be combined easily\ny ~ NormalMeanVariance(y_mean, y_var) where { q = q(μ)q(y_var)q(out) }\ny ~ NormalMeanVariance(y_mean, y_var) where { q = q(y_mean, v)q(y) }","category":"page"},{"location":"user-guide/#Metadata-option","page":"User guide","title":"Metadata option","text":"","category":"section"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"Is is possible to pass any extra metadata to a factor node with the meta option (if node supports it, read node's documentation). Metadata can be later accessed in message computation rules:","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"z ~ f(x, y) where { meta = ... }","category":"page"},{"location":"user-guide/#Pipeline-option","page":"User guide","title":"Pipeline option","text":"","category":"section"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"To assign a factor node's local pipeline we use a pipeline option:","category":"page"},{"location":"user-guide/","page":"User guide","title":"User guide","text":"y ~ NormalMeanVariance(m, v) where { pipeline = LoggerPipelineStage() } # Logs all outbound messages with `LoggerPipelineStage`","category":"page"},{"location":"user-guide/#user-guide-inference-specification","page":"User guide","title":"User guide: Inference specification","text":"","category":"section"},{"location":"user-guide/#user-guide-inference-execution","page":"User guide","title":"User guide: Inference execution","text":"","category":"section"},{"location":"distributions/#Distributions","page":"Distributions","title":"Distributions","text":"","category":"section"},{"location":"distributions/","page":"Distributions","title":"Distributions","text":"ReactiveMP.jl library uses probability distributions types from Distributions.jl package. It also provides a wider range of possible parametrisations for some probability distributions, e.g NormalMeanPrecision or MvNormalMeanPrecision which might be more efficient in some situations.","category":"page"},{"location":"#ReacitveMP.jl","page":"Home","title":"ReacitveMP.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Julia package for automatic Bayesian inference on a factor graph with reactive message passing.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Given a probabilistic model, ReactiveMP allows for an efficient message-passing based Bayesian inference. It uses the model structure to generate an algorithm that consists of a sequence of local computations on a Forney-style factor graph (FFG) representation of the model.","category":"page"},{"location":"#Package-Features","page":"Home","title":"Package Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"User friendly syntax for specification of probabilistic models.\nAutomatic generation of message passing algorithms including\nBelief propagation\nVariational message passing\nExpectation maximization\nSupport for hybrid models combining discrete and continuous latent variables.\nSupport for hybrid distinct message passing inference algorithm under a unified paradigm.\nEvaluation of Bethe free energy as a model performance measure.\nSchedule-free reactive message passing API.\nHigh performance.\nScalability for large models with millions of parameters and observations.\nInference procedure is differentiable.\nEasy to extend with custom nodes.","category":"page"},{"location":"#Resources","page":"Home","title":"Resources","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"For an introduction to message passing and FFGs, see The Factor Graph Approach to Model-Based Signal Processing by Loeliger et al. (2007).","category":"page"},{"location":"#How-to-get-started?","page":"Home","title":"How to get started?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Head to the Getting started section to get up and running with ForneyLab.","category":"page"},{"location":"#Table-of-Contents","page":"Home","title":"Table of Contents","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = [\n  \"getting-started.md\",\n  \"user-guide.md\",\n  \"extending.md\",\n  \"distributions.md\"\n]\nDepth = 2","category":"page"},{"location":"#Index","page":"Home","title":"Index","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"api/node/#node_api","page":"Node","title":"Node API","text":"","category":"section"},{"location":"api/node/","page":"Node","title":"Node","text":"Deterministic\nStochastic\nisdeterministic\nisstochastic\nsdtype\nMeanField\nFullFactorisation\ncollect_factorisation\nNodeInterface\nIndexedNodeInterface\nname\ntag\nmessageout\nmessagein","category":"page"},{"location":"api/node/#ReactiveMP.Deterministic","page":"Node","title":"ReactiveMP.Deterministic","text":"Deterministic\n\nDeterministic object used to parametrize factor node object with determinstic type of relationship between variables.\n\nSee also: Stochastic, isdeterministic, isstochastic\n\n\n\n\n\n","category":"type"},{"location":"api/node/#ReactiveMP.Stochastic","page":"Node","title":"ReactiveMP.Stochastic","text":"Stochastic\n\nStochastic object used to parametrize factor node object with stochastic type of relationship between variables.\n\nSee also: Deterministic, isdeterministic, isstochastic\n\n\n\n\n\n","category":"type"},{"location":"api/node/#ReactiveMP.isdeterministic","page":"Node","title":"ReactiveMP.isdeterministic","text":"isdeterministic(node)\n\nFunction used to check if factor node object is deterministic or not. Returns true or false.\n\nSee also: Deterministic, Stochastic, isstochastic\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.isstochastic","page":"Node","title":"ReactiveMP.isstochastic","text":"isstochastic(node)\n\nFunction used to check if factor node object is stochastic or not. Returns true or false.\n\nSee also: Deterministic, Stochastic, isdeterministic\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.sdtype","page":"Node","title":"ReactiveMP.sdtype","text":"sdtype(object)\n\nReturns either Deterministic or Stochastic for a given object (if defined).\n\nSee also: Deterministic, Stochastic, isdeterministic, isstochastic\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.MeanField","page":"Node","title":"ReactiveMP.MeanField","text":"MeanField\n\nGeneric factorisation constraint used to specify a mean-field factorisation for recognition distribution q.\n\nSee also: FullFactorisation\n\n\n\n\n\n","category":"type"},{"location":"api/node/#ReactiveMP.FullFactorisation","page":"Node","title":"ReactiveMP.FullFactorisation","text":"FullFactorisation\n\nGeneric factorisation constraint used to specify a full factorisation for recognition distribution q.\n\nSee also: MeanField\n\n\n\n\n\n","category":"type"},{"location":"api/node/#ReactiveMP.collect_factorisation","page":"Node","title":"ReactiveMP.collect_factorisation","text":"collect_factorisation(nodetype, factorisation)\n\nThis function converts given factorisation to a correct internal factorisation representation for a given node. \n\nSee also: MeanField, FullFactorisation\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.NodeInterface","page":"Node","title":"ReactiveMP.NodeInterface","text":"NodeInterface\n\nNodeInterface object represents a single node-variable connection.\n\nSee also: name, tag, messageout, messagein\n\n\n\n\n\n","category":"type"},{"location":"api/node/#ReactiveMP.IndexedNodeInterface","page":"Node","title":"ReactiveMP.IndexedNodeInterface","text":"IndexedNodeInterface\n\nIndexedNodeInterface object represents a repetative node-variable connection.  Used in cases when node may connect different number of random variables with the same name, e.g. means and precisions of Gaussian Mixture node.\n\nSee also: name, tag, messageout, messagein\n\n\n\n\n\n","category":"type"},{"location":"api/node/#ReactiveMP.name","page":"Node","title":"ReactiveMP.name","text":"name(interface)\n\nReturns a name of the interface.\n\nSee also: NodeInterface, tag\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.tag","page":"Node","title":"ReactiveMP.tag","text":"tag(interface)\n\nReturns a tag of the interface in the form of Val{ name(interface) }.  The major difference between tag and name is that it is possible to dispath on interface's tag in message computation rule.\n\nSee also: NodeInterface, name\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.messageout","page":"Node","title":"ReactiveMP.messageout","text":"messageout(interface)\n\nReturns an outbound messages stream from the given interface.\n\nSee also: NodeInterface, messagein\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.messagein","page":"Node","title":"ReactiveMP.messagein","text":"messagein(interface)\n\nReturns an inbound messages stream from the given interface.\n\nSee also: NodeInterface, messageout\n\n\n\n\n\n","category":"function"},{"location":"api/node/","page":"Node","title":"Node","text":"Internal API","category":"page"},{"location":"api/node/","page":"Node","title":"Node","text":"ReactiveMP.connectvariable!\nReactiveMP.connectedvar\nReactiveMP.connectedvarindex\nReactiveMP.get_pipeline_stages\nReactiveMP.add_pipeline_stage!\nReactiveMP.FactorNodeLocalMarginal\nReactiveMP.FactorNodeLocalMarginals","category":"page"},{"location":"api/node/#ReactiveMP.connectvariable!","page":"Node","title":"ReactiveMP.connectvariable!","text":"connectvariable!(interface, variable, index)\n\nConnects a variable with the interface and given index. Index is used to distinguish this connection from others in case if variable is connected to multiple interfaces.\n\nSee also: NodeInterface, connectedvar, connectedvarindex\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.connectedvar","page":"Node","title":"ReactiveMP.connectedvar","text":"connectedvar(interface)\n\nReturns connected variable for the interface.\n\nSee also: NodeInterface, connectvariable!, connectedvarindex\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.connectedvarindex","page":"Node","title":"ReactiveMP.connectedvarindex","text":"connectedvarindex(interface)\n\nReturns an index of connected variable for the interface.\n\nSee also: NodeInterface, connectvariable!, connectedvar\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.get_pipeline_stages","page":"Node","title":"ReactiveMP.get_pipeline_stages","text":"get_pipeline_stages(interface)\n\nReturns an instance of pipeline stages of connected variable for the given interface\n\nSee also: NodeInterface, connectvariable!, connectedvar, add_inbound_pipeline_stage!\n\n\n\n\n\n","category":"function"},{"location":"api/node/#ReactiveMP.FactorNodeLocalMarginal","page":"Node","title":"ReactiveMP.FactorNodeLocalMarginal","text":"FactorNodeLocalMarginal\n\nThis object represents local marginals for some specific factor node.  Local marginal can be joint in case of structured factorisation.  Local to factor node marginal also can be shared with a corresponding marginal of some random variable.\n\nSee also: FactorNodeLocalMarginals\n\n\n\n\n\n","category":"type"},{"location":"api/node/#ReactiveMP.FactorNodeLocalMarginals","page":"Node","title":"ReactiveMP.FactorNodeLocalMarginals","text":"FactorNodeLocalMarginals\n\nThis object acts as an iterable and indexable proxy for local marginals for some node. \n\n\n\n\n\n","category":"type"}]
}
